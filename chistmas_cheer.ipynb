{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from imports import *\n",
    "# sklearn\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans as sklearn_kmeans\n",
    "from sklearn import metrics\n",
    "from  sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "from datetime import datetime\n",
    "%matplotlib inline\n",
    "#sqlContext = SQLContext(sc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "with open(\"./data/values.csv\",'rb') as f:\n",
    "    values = np.array([ [float(item) for item in line.strip().split(',')] for line in f ])\n",
    "print values.shape\n",
    "with open('./data/labels.csv','rb') as f:\n",
    "    labels = np.ravel( np.array([ line.strip().split(',') for line in f ]) )\n",
    "print labels.shape\n",
    "with open('./data/test-values.csv','rb') as f:\n",
    "    test_values = np.array([ [float(item) for item in line.strip().split(',')] for line in f ])\n",
    "print test_values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission file\n",
    "<pre>\n",
    "# comment\n",
    "# comment\n",
    "team name, make this consistent across all submissions. This will appear in the leader board.>\n",
    "timestamp of sumbission in format 2015-12-xxT00:00:00\n",
    "submission name-anything you want. This will appear in the leader board.\n",
    "# data is 1 integer per row. there should be 10000 of them.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_submission_file(submission_name,comment,fileName,pred):\n",
    "    team_name = 'blehmanade'\n",
    "    timestamp = datetime.now()\n",
    "    header = '#{}\\n{}\\n{}\\n{}\\n'.format(comment,team_name,timestamp,submission_name)\n",
    "    with open(fileName,'wb') as submission:\n",
    "        submission.write(header)\n",
    "        for prediction in predictions:\n",
    "            submission.write(prediction+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nbrs = KNeighborsClassifier(n_neighbors=10, algorithm='ball_tree').fit(values, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/KNeighborsClassifier_ball_tree_n10.pkl','wb') as f:\n",
    "    pickle.dump(nbrs,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = nbrs.predict(test_values)\n",
    "with open('data/KNeighborsClassifier_ball_tree_n10_predictions.pkl','wb') as f:\n",
    "    pickle.dump(predictions,f)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comment = \"KNeighborsClassifier(n_neighbors=10, algorithm='ball_tree').fit(values, labels)\"\n",
    "fileName = 'KNeighborsClassifier_ball_tree_n10_predictions.submission'\n",
    "submission_name = 'love_thy_neighbor'\n",
    "create_submission_file(submission_name,comment,fileName,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/KNeighborsClassifier_ball_tree_n10.pkl','rb') as f:\n",
    "    nbrs = pickle.load(f)\n",
    "nbrs.score(values, labels) # output: 0.97499999999999998"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nbrs = KNeighborsClassifier(n_neighbors=10, algorithm='kd_tree').fit(values, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = nbrs.predict(test_values)\n",
    "with open('data/KNeighborsClassifier_kd_tree_n10_predictions.pkl','wb') as f:\n",
    "    pickle.dump(predictions,f)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comment = \"KNeighborsClassifier(n_neighbors=10, algorithm='kd_tree').fit(values, labels)\"\n",
    "fileName = 'KNeighborsClassifier_kd_tree_n10_predictions.submission'\n",
    "submission_name = 'kid_neighbors_tree_fort'\n",
    "create_submission_file(submission_name,comment,fileName,predictions)\n",
    "!tail KNeighborsClassifier_kd_tree_n10_predictions.submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nbrs = KNeighborsClassifier(n_neighbors=10, algorithm='brute').fit(values, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = nbrs.predict(test_values)\n",
    "fileName = 'KNeighborsClassifier_brute_n10_predictions'\n",
    "with open('data/'+fileName+'.pkl','wb') as f:\n",
    "    pickle.dump(predictions,f)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comment = \"KNeighborsClassifier(n_neighbors=10, algorithm='kd_tree').fit(values, labels)\"\n",
    "submission_name = 'brutal_neighbors'\n",
    "create_submission_file(submission_name,comment,fileName+'.submission',predictions)\n",
    "!tail KNeighborsClassifier_brute_n10_predictions.submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier().fit(values,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/AdaBoostClassifier.pkl','wb') as f:\n",
    "    pickle.dump(ada,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = ada.predict(test_values)\n",
    "fileName = 'adaBoost_SGDClassifier_predictions'\n",
    "with open('data/'+fileName+'.pkl','wb') as f:\n",
    "    pickle.dump(predictions,f)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comment = \"AdaBoostClassifier().fit(values,labels)\"\n",
    "submission_name = 'adaboy_charlie_brown'\n",
    "create_submission_file(submission_name,comment,fileName+'.submission',predictions)\n",
    "!head adaBoost_DecisionTreeClassifier_predictions.submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ada.score(values,labels) #output: 0.7265166666666667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(base_estimator=SGDClassifier(),algorithm='SAMME').fit(values,labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print ada.score(values,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = ada.predict(test_values)\n",
    "fileName = 'adaBoost_SGDClassifier_predictions'\n",
    "with open('data/'+fileName+'.pkl','wb') as f:\n",
    "    pickle.dump(predictions,f)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comment = \"AdaBoostClassifier(base_estimator=SGDClassifier(),algorithm='SAMME').fit(values,labels)\"\n",
    "submission_name = 'ada_unicorn'\n",
    "create_submission_file(submission_name,comment,fileName+'.submission',predictions)\n",
    "!head adaBoost_SGDClassifier_predictions.submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 6\n",
    "SVD (n_components=20) to reduce the dimensions in the dataset for KNN.\n",
    "<img src=\"./img/method6.png\" alt=\"Drawing\" style=\"width: 250px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from sklearn.decomposition import TruncatedSVD\n",
    "explained_variance = []\n",
    "svd_component_range = range(0,91,5)\n",
    "for i in svd_component_range:\n",
    "    if i == 0:\n",
    "        i = 1\n",
    "    svd = TruncatedSVD(n_components=i, random_state=42)\n",
    "    X_svd = svd.fit_transform(values)\n",
    "    explained_variance.append(svd.explained_variance_ratio_.sum())\n",
    "    print i\n",
    "\n",
    "expVar = pd.DataFrame({'components':svd_component_range\n",
    "                       ,'explained_variance':explained_variance\n",
    "                      })\n",
    "display(expVar)\n",
    "display(expVar.plot(x='components',y='explained_variance'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=20, random_state=42)\n",
    "X_svd = svd.fit_transform(values)\n",
    "nbrs = KNeighborsClassifier(n_neighbors=10, algorithm='ball_tree').fit(X_svd, labels)\n",
    "#predictions = nbrs.predict(test_values)\n",
    "score = nbrs.score(X_svd, labels)\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(type(test_values))\n",
    "display(test_values.shape)\n",
    "display(test_values[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = svd.transform(test_values)\n",
    "predictions = nbrs.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fileName = 'KNeighborsClassifier_ball_tree_n10_SVD20'\n",
    "with open('data/'+fileName+'.pkl','wb') as f:\n",
    "    pickle.dump(predictions,f)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comment = \"KNeighborsClassifier(n_neighbors=10, algorithm='ball_tree').fit(X_svd, labels)\"\n",
    "submission_name = 'unicorn_next_door'\n",
    "create_submission_file(submission_name,comment,fileName+'.submission',predictions)\n",
    "!head KNeighborsClassifier_ball_tree_n10_SVD20.submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 6b\n",
    "SVD (n_components=90) to reduce the dimensions in the dataset for KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=90, random_state=42)\n",
    "X_svd = svd.fit_transform(values)\n",
    "nbrs = KNeighborsClassifier(n_neighbors=10, algorithm='ball_tree').fit(X_svd, labels)\n",
    "predictions = nbrs.predict(svd.transform(test_values))\n",
    "#score = nbrs.score(X_svd, labels)\n",
    "#print score\n",
    "fileName = 'KNeighborsClassifier_ball_tree_n10_SVD90'\n",
    "with open('data/'+fileName+'.pkl','wb') as f:\n",
    "    pickle.dump(predictions,f)\n",
    "print predictions.shape\n",
    "submission_name = 'unicorn_next_door_more'\n",
    "create_submission_file(submission_name,comment,fileName+'.submission',predictions)\n",
    "!head KNeighborsClassifier_ball_tree_n10_SVD90.submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = nbrs.score(X_svd, labels)\n",
    "print score # output: 0.9792"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 6c \n",
    "Playing with the number of components from 6b.  \n",
    "\n",
    "note: `labels = np.ravel(labels)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svd_component_range = range(89,120)\n",
    "scores = []\n",
    "for i in svd_component_range:\n",
    "    if i == 90:\n",
    "        continue\n",
    "    svd = TruncatedSVD(n_components=i, random_state=42)\n",
    "    X_svd = svd.fit_transform(values)\n",
    "    nbrs = KNeighborsClassifier(n_neighbors=10, algorithm='ball_tree').fit(X_svd, labels)\n",
    "    score = nbrs.score(X_svd, labels)\n",
    "    scores.append(score)\n",
    "    print \"{}: {}\".format(i,score)\n",
    "    #score = nbrs.score(X_svd, labels)\n",
    "    #print score\n",
    "    predictions = nbrs.predict(svd.transform(test_values))\n",
    "    fileName = 'KNeighborsClassifier_ball_tree_n10_SVD'+str(i)\n",
    "    with open('data/'+fileName+'.pkl','wb') as f:\n",
    "        pickle.dump(predictions,f)\n",
    "    submission_name = 'mo_unicorn'+str(i)\n",
    "    create_submission_file(submission_name,comment,fileName+'.submission',predictions)\n",
    "scores_df = pd.DataFrame({'components': svd_component_range\n",
    "                       ,'scores':scores\n",
    "                      })\n",
    "display(scores_df)\n",
    "display(scores_df.plot(x='components',y='scores'))\n",
    "\n",
    "#89: 0.97935\n",
    "#91: 0.979133333333\n",
    "#92: 0.9791\n",
    "#93: 0.9791\n",
    "#94: 0.97925\n",
    "#95: 0.97905"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svd_component_range = range(90,58,-2)\n",
    "svd_component_range.remove(90)\n",
    "scores = []\n",
    "for i in svd_component_range:\n",
    "    svd = TruncatedSVD(n_components=i, random_state=42)\n",
    "    X_svd = svd.fit_transform(values)\n",
    "    nbrs = KNeighborsClassifier(n_neighbors=10, algorithm='ball_tree').fit(X_svd, labels)\n",
    "    score = nbrs.score(X_svd, labels)\n",
    "    scores.append(score)\n",
    "    print \"{}: {}\".format(i,score)\n",
    "    #score = nbrs.score(X_svd, labels)\n",
    "    #print score\n",
    "    predictions = nbrs.predict(svd.transform(test_values))\n",
    "    fileName = 'KNeighborsClassifier_ball_tree_n10_SVD'+str(i)\n",
    "    with open('data/'+fileName+'.pkl','wb') as f:\n",
    "        pickle.dump(predictions,f)\n",
    "    submission_name = 'mo_unicorn'+str(i)\n",
    "    create_submission_file(submission_name,comment,fileName+'.submission',predictions)\n",
    "scores_df = pd.DataFrame({'components': svd_component_range\n",
    "                       ,'scores':scores\n",
    "                      })\n",
    "display(scores_df)\n",
    "display(scores_df.plot(x='components',y='scores'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"./img/method6b2.png\" alt=\"Drawing\" style=\"width: 250px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "components\tscores  \n",
    "0\t58\t0.980583  \n",
    "1\t56\t0.980483  \n",
    "2\t54\t0.980800  \n",
    "3\t52\t0.980683  \n",
    "4\t50\t0.980850  \n",
    "5\t48\t0.980783  \n",
    "6\t46\t0.980633  \n",
    "7\t44\t0.980583  \n",
    "8\t42\t0.980417  \n",
    "9\t40\t0.980567  \n",
    "10\t38\t0.980400  \n",
    "11\t36\t0.980467  \n",
    "12\t34\t0.980250  \n",
    "13\t32\t0.980050  \n",
    "14\t30\t0.980000  \n",
    "15\t28\t0.979100  \n",
    "16\t26\t0.978683  \n",
    "17\t24\t0.978000  \n",
    "18\t22\t0.977317  \n",
    "19\t20\t0.974817  \n",
    "20\t18\t0.972900  \n",
    "21\t16\t0.970883  \n",
    "<img src=\"./img/method6b.png\" alt=\"Drawing\" style=\"width: 250px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svd_component_range = range(60,14,-2)\n",
    "svd_component_range.remove(60)\n",
    "scores = []\n",
    "for i in svd_component_range:\n",
    "    svd = TruncatedSVD(n_components=i, random_state=42)\n",
    "    X_svd = svd.fit_transform(values)\n",
    "    nbrs = KNeighborsClassifier(n_neighbors=10, algorithm='ball_tree').fit(X_svd, labels)\n",
    "    score = nbrs.score(X_svd, labels)\n",
    "    scores.append(score)\n",
    "    print \"{}: {}\".format(i,score)\n",
    "    #score = nbrs.score(X_svd, labels)\n",
    "    #print score\n",
    "    predictions = nbrs.predict(svd.transform(test_values))\n",
    "    fileName = 'KNeighborsClassifier_ball_tree_n10_SVD'+str(i)\n",
    "    with open('data/'+fileName+'.pkl','wb') as f:\n",
    "        pickle.dump(predictions,f)\n",
    "    submission_name = 'mo_unicorn'+str(i)\n",
    "    create_submission_file(submission_name,comment,fileName+'.submission',predictions)\n",
    "scores_df = pd.DataFrame({'components': svd_component_range\n",
    "                       ,'scores':scores\n",
    "                      })\n",
    "display(scores_df)\n",
    "display(scores_df.plot(x='components',y='scores'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 7\n",
    "Consider using PCA with Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_component_range = range(0,81,5)\n",
    "explained_variance_list = []\n",
    "for i in pca_component_range:\n",
    "    if i == 0:\n",
    "        i=1\n",
    "    X_pca = PCA(n_components=i).fit(values)\n",
    "    explained_var = X_pca.explained_variance_ratio_.sum()\n",
    "    print \"{}: {}\".format(i, explained_var)\n",
    "    explained_variance_list.append(explained_var)\n",
    "scores_df = pd.DataFrame({'components': pca_component_range\n",
    "                       ,'explained_variance':explained_variance_list\n",
    "                      })\n",
    "display(scores_df)\n",
    "display(scores_df.plot(x='components',y='explained_variance'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=80).fit(values)\n",
    "X_pca = pca.transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "km = sklearn_kmeans(n_clusters=10).fit(X_pca,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = km.predict(pca.transform(test_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bench_k_means(estimator, name, data):\n",
    "    t0 = time()\n",
    "    estimator.fit(data)\n",
    "    print('% 9s   %.2fs    %i   %.3f   %.3f   %.3f   %.3f   %.3f'\n",
    "          % (name, (time() - t0), estimator.inertia_,\n",
    "             metrics.homogeneity_score(labels, estimator.labels_),\n",
    "             metrics.completeness_score(labels, estimator.labels_),\n",
    "             metrics.v_measure_score(labels, estimator.labels_),\n",
    "             metrics.adjusted_rand_score(labels, estimator.labels_),\n",
    "             metrics.adjusted_mutual_info_score(labels,  estimator.labels_)\n",
    "           ))\n",
    "\n",
    "# k-means++   91.27s    152992542352   0.485   0.496   0.490   0.361   0.485\n",
    "#bench_k_means(sklearn_kmeans(init='k-means++', n_clusters=10, n_init=10), name=\"k-means++\", data=values)\n",
    "\n",
    "# PCA-based   31.59s    114256441871   0.765   0.418   0.541   0.196   0.418\n",
    "bench_k_means(sklearn_kmeans(init=pca.components_, n_clusters=10, n_init=1), name=\"PCA-based\", data=values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 8\n",
    "Consider using `sklear.preprocessing.scale` to scale the data from the mean, then apply PCA and Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 9\n",
    "[linear-support-vector-machines](http://www.scipy-lectures.org/packages/scikit-learn/#linear-support-vector-machines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svc = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc.fit(X_pca, labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc.score(values, labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='poly', degree=3)\n",
    "svc = svm.SVC(kernel='rbf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 10\n",
    "GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unbound method fit_transform() must be called with GradientBoostingClassifier instance as first argument (got ndarray instance instead)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6371711cb590>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgboost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unbound method fit_transform() must be called with GradientBoostingClassifier instance as first argument (got ndarray instance instead)"
     ]
    }
   ],
   "source": [
    "gboost = GradientBoostingClassifier.fit_transform(values,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 11 \n",
    "NearestCentroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "for shrinkage in [None,0.1, 0.5,1.5,2.5]: \n",
    "    nc = NearestCentroid(shrink_threshold=shrinkage).fit(values, labels)\n",
    "    predictions[str(shrinkage)] = nc.predict(test_values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vals = [ a-b for a,b in zip([int(i) for i in predictions['None']], [int(i) for i in predictions['0.1']]) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "2\n",
      "2\n",
      "9\n",
      "1\n",
      "5\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for item in vals:\n",
    "    if item !=0:\n",
    "        print item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for prediction in predictions:\n",
    "    fileName = 'NearestCentroid_shrinkage_'+str(prediction)\n",
    "    with open('data/'+fileName+'.pkl','wb') as f:\n",
    "        pickle.dump(predictions[prediction],f)\n",
    "    comment = 'NearestCentroid(shrink_threshold=shrinkage).fit(values, labels)'\n",
    "    submission_name = 'ity_bity_'+prediction\n",
    "    create_submission_file(submission_name,comment,fileName+'.submission',predictions[prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80774999999999997"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc = NearestCentroid(shrink_threshold=2.5).fit(values, labels)\n",
    "nc.score(values,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 12 \n",
    "BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97511666666666663"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging = BaggingClassifier(KNeighborsClassifier(),max_samples=0.5, max_features=0.5)\n",
    "bg = bagging.fit(values,labels)\n",
    "bg.score(values,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = bg.predict(test_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['7', '2', '1', '0', '4', '1', '4', '9', '5', '9'], \n",
       "      dtype='|S1')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('BaggingClassifier_KNeighborsClassifier_max_samples0.5_max_features0.5'+'.pkl','wb') as bgFile:\n",
    "    pickle.dump(bg,bgFile)\n",
    "with open('BaggingClassifier_KNeighborsClassifier_max_samples0.5_max_features0.5_predictions'+'.pkl','wb') as bgFile:\n",
    "    pickle.dump(predictions,bgFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileName='BaggingClassifier_KNeighborsClassifier_max_samples0.5_max_features0.5'\n",
    "comment = 'BaggingClassifier(KNeighborsClassifier(),max_samples=0.5, max_features=0.5)'\n",
    "submission_name = 'we_gotta_first_timer_here'\n",
    "create_submission_file(submission_name,comment,fileName+'.submission',predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.980583333333\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "X_svd = svd.fit_transform(values)\n",
    "bagging = BaggingClassifier(KNeighborsClassifier(n_neighbors=10))\n",
    "bg = bagging.fit(X_svd,labels)\n",
    "print bg.score(X_svd,labels)\n",
    "predictions = bg.predict(svd.transform(test_values))\n",
    "fileName='BaggingClassifier_KNeighborsClassifier_n_neighbors10_svd_'\n",
    "with open(fileName+'model'+'.pkl','wb') as bgFile:\n",
    "    pickle.dump(bg,bgFile)\n",
    "with open(fileName+'predictions'+'.pkl','wb') as bgFile:\n",
    "    pickle.dump(predictions,bgFile)\n",
    "comment = 'BaggingClassifier(KNeighborsClassifier(n_neighbors=10))'\n",
    "submission_name = 'movie_night:  http://bit.ly/pooty'\n",
    "create_submission_file(submission_name,comment,fileName+'.submission',predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 50)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_svd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97925\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=100, random_state=42)\n",
    "X_svd = svd.fit_transform(values)\n",
    "bagging = BaggingClassifier(KNeighborsClassifier(n_neighbors=10),max_features=0.5)\n",
    "bg = bagging.fit(X_svd,labels)\n",
    "print bg.score(X_svd,labels)\n",
    "predictions = bg.predict(svd.transform(test_values))\n",
    "fileName='BaggingClassifier_KNeighborsClassifier_n_neighbors10_svd_'\n",
    "with open(fileName+'model'+'.pkl','wb') as bgFile:\n",
    "    pickle.dump(bg,bgFile)\n",
    "with open(fileName+'predictions'+'.pkl','wb') as bgFile:\n",
    "    pickle.dump(predictions,bgFile)\n",
    "comment = 'BaggingClassifier(KNeighborsClassifier(n_neighbors=10))'\n",
    "submission_name = 'movie_night:  http://bit.ly/pooty'\n",
    "create_submission_file(submission_name,comment,fileName+'.submission',predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {'algorithm' : ['ball_tree', 'kd_tree']\n",
    "              ,'leaf_size' : [10,30,50,100]\n",
    "              ,'metric': ['euclidean','manhattan','chebyshev','minkowski','wminkowski','seuclidean','mahalanobis','hamming','canberra','braycurtis']\n",
    "              ,'n_neighbors':[1,5,11,21,31]\n",
    "             }\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid)\n",
    "grid_search.fit(values,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report(grid_scores, n_top=3):\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "              score.mean_validation_score,\n",
    "              np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "report(grid_search.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('grid_search.pkl','wb') as f:\n",
    "    pickle.dump(grid_search,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
